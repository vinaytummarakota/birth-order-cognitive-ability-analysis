)
cleaned_df <- clean_df(df, colnames(df), new_cols, dropped_cols)
write.csv(cleaned_df, "cleaned_nlsy79_data.csv", row.names = FALSE)
View(cleaned_df)
nrow(cleaned_df)
View(cleaned_df %>% filter(is_likely_dz_twin == TRUE) %>% select(case_id, family_id, birth_order))
knitr::opts_chunk$set(echo = TRUE)
source("./01_helper_functions.R")
df <- read.csv("../00_raw_nlsy_data/birth_order_analysis_vars.csv")
new_cols <- c(
"case_id",
"family_id",
"birth_order",
"sample_id",
"race",
"sex",
"month_of_birth",
"year_of_birth",
"month_of_1981_interview",
"sampling_weight",
"asvab_section_1_general_science",
"asvab_section_2_arithmetic_reasoning",
"asvab_section_3_word_knowledge",
"asvab_section_4_paragraph_comprehension",
"asvab_section_5_numerical_operations",
"asvab_section_6_coding_speed",
"asvab_section_7_auto_and_shop_info",
"asvab_section_8_mathematics_knowledge",
"asvab_section_9_mechanical_comp",
"asvab_section_10_electronics_info",
"age_at_interview"
)
# these columns automatically accompany the NLSY data but will not be used in this analysis
dropped_cols <- c(
"race",
"sex"
)
cleaned_df <- clean_df(df, colnames(df), new_cols, dropped_cols)
knitr::opts_chunk$set(echo = TRUE)
source("./01_helper_functions.R")
df <- read.csv("../00_raw_nlsy_data/birth_order_analysis_vars.csv")
new_cols <- c(
"case_id",
"family_id",
"birth_order",
"sample_id",
"race",
"sex",
"month_of_birth",
"year_of_birth",
"month_of_1981_interview",
"sampling_weight",
"asvab_section_1_general_science",
"asvab_section_2_arithmetic_reasoning",
"asvab_section_3_word_knowledge",
"asvab_section_4_paragraph_comprehension",
"asvab_section_5_numerical_operations",
"asvab_section_6_coding_speed",
"asvab_section_7_auto_and_shop_info",
"asvab_section_8_mathematics_knowledge",
"asvab_section_9_mechanical_comp",
"asvab_section_10_electronics_info",
"age_at_interview"
)
# these columns automatically accompany the NLSY data but will not be used in this analysis
dropped_cols <- c(
"race",
"sex"
)
cleaned_df <- clean_df(df, colnames(df), new_cols, dropped_cols)
knitr::opts_chunk$set(echo = TRUE)
source("./01_helper_functions.R")
df <- read.csv("../00_raw_nlsy_data/birth_order_analysis_vars.csv")
new_cols <- c(
"case_id",
"family_id",
"birth_order",
"sample_id",
"race",
"sex",
"month_of_birth",
"year_of_birth",
"month_of_1981_interview",
"sampling_weight",
"asvab_section_1_general_science",
"asvab_section_2_arithmetic_reasoning",
"asvab_section_3_word_knowledge",
"asvab_section_4_paragraph_comprehension",
"asvab_section_5_numerical_operations",
"asvab_section_6_coding_speed",
"asvab_section_7_auto_and_shop_info",
"asvab_section_8_mathematics_knowledge",
"asvab_section_9_mechanical_comp",
"asvab_section_10_electronics_info",
"age_at_interview"
)
# these columns automatically accompany the NLSY data but will not be used in this analysis
dropped_cols <- c(
"race",
"sex"
)
cleaned_df <- clean_df(df, colnames(df), new_cols, dropped_cols)
knitr::opts_chunk$set(echo = TRUE)
source("./01_helper_functions.R")
df <- read.csv("../00_raw_nlsy_data/birth_order_analysis_vars.csv")
new_cols <- c(
"case_id",
"family_id",
"birth_order",
"sample_id",
"race",
"sex",
"month_of_birth",
"year_of_birth",
"month_of_1981_interview",
"sampling_weight",
"asvab_section_1_general_science",
"asvab_section_2_arithmetic_reasoning",
"asvab_section_3_word_knowledge",
"asvab_section_4_paragraph_comprehension",
"asvab_section_5_numerical_operations",
"asvab_section_6_coding_speed",
"asvab_section_7_auto_and_shop_info",
"asvab_section_8_mathematics_knowledge",
"asvab_section_9_mechanical_comp",
"asvab_section_10_electronics_info",
"age_at_interview"
)
# these columns automatically accompany the NLSY data but will not be used in this analysis
dropped_cols <- c(
"race",
"sex"
)
cleaned_df <- clean_df(df, colnames(df), new_cols, dropped_cols)
knitr::opts_chunk$set(echo = TRUE)
source("./01_helper_functions.R")
df <- read.csv("../00_raw_nlsy_data/birth_order_analysis_vars.csv")
new_cols <- c(
"case_id",
"family_id",
"birth_order",
"sample_id",
"race",
"sex",
"month_of_birth",
"year_of_birth",
"month_of_1981_interview",
"sampling_weight",
"asvab_section_1_general_science",
"asvab_section_2_arithmetic_reasoning",
"asvab_section_3_word_knowledge",
"asvab_section_4_paragraph_comprehension",
"asvab_section_5_numerical_operations",
"asvab_section_6_coding_speed",
"asvab_section_7_auto_and_shop_info",
"asvab_section_8_mathematics_knowledge",
"asvab_section_9_mechanical_comp",
"asvab_section_10_electronics_info",
"age_at_interview"
)
# these columns automatically accompany the NLSY data but will not be used in this analysis
dropped_cols <- c(
"race",
"sex"
)
cleaned_df <- clean_df(df, colnames(df), new_cols, dropped_cols)
write.csv(cleaned_df, "cleaned_nlsy79_data.csv", row.names = FALSE)
nrow(cleaned_df)
View(cleaned_df %>% filter(is_likely_dz_twin == TRUE) %>% select(case_id, family_id, birth_order, estimated_age,is_selected_twin))
knitr::opts_chunk$set(echo = TRUE)
source("./01_helper_functions.R")
df <- read.csv("../00_raw_nlsy_data/birth_order_analysis_vars.csv")
new_cols <- c(
"case_id",
"family_id",
"birth_order",
"sample_id",
"race",
"sex",
"month_of_birth",
"year_of_birth",
"month_of_1981_interview",
"sampling_weight",
"asvab_section_1_general_science",
"asvab_section_2_arithmetic_reasoning",
"asvab_section_3_word_knowledge",
"asvab_section_4_paragraph_comprehension",
"asvab_section_5_numerical_operations",
"asvab_section_6_coding_speed",
"asvab_section_7_auto_and_shop_info",
"asvab_section_8_mathematics_knowledge",
"asvab_section_9_mechanical_comp",
"asvab_section_10_electronics_info",
"age_at_interview"
)
# these columns automatically accompany the NLSY data but will not be used in this analysis
dropped_cols <- c(
"race",
"sex"
)
cleaned_df <- clean_df(df, colnames(df), new_cols, dropped_cols)
write.csv(cleaned_df, "cleaned_nlsy79_data.csv", row.names = FALSE)
View(cleaned_df %>% filter(is_likely_dz_twin == TRUE) %>% select(case_id, family_id, birth_order, estimated_age, is_selected_twin))
knitr::opts_chunk$set(echo = TRUE)
source("./01_helper_functions.R")
df <- read.csv("../00_raw_nlsy_data/birth_order_analysis_vars.csv")
new_cols <- c(
"case_id",
"family_id",
"birth_order",
"sample_id",
"race",
"sex",
"month_of_birth",
"year_of_birth",
"month_of_1981_interview",
"sampling_weight",
"asvab_section_1_general_science",
"asvab_section_2_arithmetic_reasoning",
"asvab_section_3_word_knowledge",
"asvab_section_4_paragraph_comprehension",
"asvab_section_5_numerical_operations",
"asvab_section_6_coding_speed",
"asvab_section_7_auto_and_shop_info",
"asvab_section_8_mathematics_knowledge",
"asvab_section_9_mechanical_comp",
"asvab_section_10_electronics_info",
"age_at_interview"
)
# these columns automatically accompany the NLSY data but will not be used in this analysis
dropped_cols <- c(
"race",
"sex"
)
cleaned_df <- clean_df(df, colnames(df), new_cols, dropped_cols)
knitr::opts_chunk$set(echo = TRUE)
source("./01_helper_functions.R")
knitr::opts_chunk$set(echo = TRUE)
source("./01_helper_functions.R")
knitr::opts_chunk$set(echo = TRUE)
source("./01_helper_functions.R")
df <- read.csv("../00_raw_nlsy_data/birth_order_analysis_vars.csv")
new_cols <- c(
"case_id",
"family_id",
"birth_order",
"sample_id",
"race",
"sex",
"month_of_birth",
"year_of_birth",
"month_of_1981_interview",
"sampling_weight",
"asvab_section_1_general_science",
"asvab_section_2_arithmetic_reasoning",
"asvab_section_3_word_knowledge",
"asvab_section_4_paragraph_comprehension",
"asvab_section_5_numerical_operations",
"asvab_section_6_coding_speed",
"asvab_section_7_auto_and_shop_info",
"asvab_section_8_mathematics_knowledge",
"asvab_section_9_mechanical_comp",
"asvab_section_10_electronics_info",
"age_at_interview"
)
# these columns automatically accompany the NLSY data but will not be used in this analysis
dropped_cols <- c(
"race",
"sex"
)
cleaned_df <- clean_df(df, colnames(df), new_cols, dropped_cols)
write.csv(cleaned_df, "cleaned_nlsy79_data.csv", row.names = FALSE)
nrow(cleaned_df)
knitr::opts_chunk$set(echo = TRUE)
source("./01_helper_functions.R")
df <- read.csv("../00_raw_nlsy_data/birth_order_analysis_vars.csv")
new_cols <- c(
"case_id",
"family_id",
"birth_order",
"sample_id",
"race",
"sex",
"month_of_birth",
"year_of_birth",
"month_of_1981_interview",
"sampling_weight",
"asvab_section_1_general_science",
"asvab_section_2_arithmetic_reasoning",
"asvab_section_3_word_knowledge",
"asvab_section_4_paragraph_comprehension",
"asvab_section_5_numerical_operations",
"asvab_section_6_coding_speed",
"asvab_section_7_auto_and_shop_info",
"asvab_section_8_mathematics_knowledge",
"asvab_section_9_mechanical_comp",
"asvab_section_10_electronics_info",
"age_at_interview"
)
# these columns automatically accompany the NLSY data but will not be used in this analysis
dropped_cols <- c(
"race",
"sex"
)
cleaned_df <- clean_df(df, colnames(df), new_cols, dropped_cols)
write.csv(cleaned_df, "cleaned_nlsy79_data.csv", row.names = FALSE)
nrow(cleaned_df)
nrow(cleaned_df %>% filter(is_in_two_sibling_sample))
nrow(cleaned_df %>% filter(is_in_three_sibling_sample))
538/3
1479/2
gc()
knitr::opts_chunk$set(echo = TRUE)
source("./01_helper_functions.R")
df <- read.csv("../00_raw_nlsy_data/birth_order_analysis_vars.csv")
new_cols <- c(
"case_id",
"family_id",
"birth_order",
"sample_id",
"race",
"sex",
"month_of_birth",
"year_of_birth",
"month_of_1981_interview",
"sampling_weight",
"asvab_section_1_general_science",
"asvab_section_2_arithmetic_reasoning",
"asvab_section_3_word_knowledge",
"asvab_section_4_paragraph_comprehension",
"asvab_section_5_numerical_operations",
"asvab_section_6_coding_speed",
"asvab_section_7_auto_and_shop_info",
"asvab_section_8_mathematics_knowledge",
"asvab_section_9_mechanical_comp",
"asvab_section_10_electronics_info",
"age_at_interview"
)
# these columns automatically accompany the NLSY data but will not be used in this analysis
dropped_cols <- c(
"race",
"sex"
)
cleaned_df <- clean_df(df, colnames(df), new_cols, dropped_cols)
write.csv(cleaned_df, "cleaned_nlsy79_data.csv", row.names = FALSE)
cleaned_df %>% filter(
is_in_three_sibling_sample == TRUE
) %>%
group_by(
family_id
) %>%
summarise(
count = n()
) %>%
arrange(
desc(count)
)
cleaned_df %>% filter(family_id == "11826")
View(cleaned_df %>% filter(family_id == "11826"))
cleaned_df %>% filter(
is_in_three_sibling_sample == TRUE
) %>%
group_by(
family_id
) %>%
summarise(
count = n()
) %>%
filter(
count != 3
)
cleaned_df %>% filter(
is_in_two_sibling_sample == TRUE
) %>%
group_by(
family_id
) %>%
summarise(
count = n()
) %>%
filter(
count != 2
)
View(cleaned_df %>% filter(family_id %in% c(684, 8253, 11826)))
Links79Pair %>% filter(R == 0.5, RelationshipPath == 'Gen1Housemates', ExtendedID == 684)
cleaned_df %>%
filter(is_in_three_sibling_sample == TRUE) %>%
group_by(
birth_order
) %>%
summarise(
across(select(starts_with("asvab")), mean(na.rm = TRUE))
)
cleaned_df %>%
filter(is_in_three_sibling_sample == TRUE) %>%
group_by(
birth_order
) %>%
summarise(
across(select(starts_with("asvab")), ~ mean(.x, na.rm = TRUE))
)
cleaned_df %>%
filter(is_in_three_sibling_sample == TRUE) %>%
group_by(
birth_order
) %>%
summarise(
across(starts_with("asvab"), ~ mean(.x, na.rm = TRUE))
)
cleaned_df %>%
filter(is_in_three_sibling_sample == TRUE) %>%
group_by(
birth_order
) %>%
summarise(
across(starts_with("asvab"), ~ sd(.x, na.rm = TRUE))
)
cleaned_df %>%
filter(is_in_two_sibling_sample == TRUE) %>%
group_by(
birth_order
) %>%
summarise(
across(starts_with("asvab"), ~ mean(.x, na.rm = TRUE))
)
?data.frame
library(metafor)
?rma
rma(data = df, yi = effect_size, sei = standard_error, slab = city)
df <- data.frame(city = c("Los Angeles", "San Francisco"), effect_size = c(25.22, 15.99), standard_error = c(11.27, 12.66))
rma(data = df, yi = effect_size, sei = standard_error, slab = city)
meta_analysis <- rma(data = df, yi = effect_size, sei = standard_error, slab = city)
meta_analysis$beta
meta_analysis$se
meta_analysis$beta[1]
meta_analysis$se[1]
meta_analysis <- rma(data = df, yi = effect_size, sei = standard_error, slab = city)
df <- rbind(
df,
c(meta_analysis$beta[1], meta_analysis$se[1])
)
df
df <- data.frame(city = c("Los Angeles", "San Francisco"), effect_size = c(25.22, 15.99), standard_error = c(11.27, 12.66))
meta_analysis <- rma(data = df, yi = effect_size, sei = standard_error, slab = city)
df <- rbind(
df,
c("Meta-Analysis", meta_analysis$beta[1], meta_analysis$se[1])
)
df
library(ggplot)
library(ggplot2)
ggplot(df, aes(x = city, y = effect_size)) +
geom_point()+
geom_errorbar(ymin = effect_size + 1.96 * standard_error, ymax = effect_size + 1.96 * standard_error)
ggplot(df, aes(x = city, y = effect_size)) +
geom_point()+
geom_errorbar(ymin = effect_size + 1.96 * standard_error, ymax = effect_size + 1.96 * standard_error)
df <- data.frame(city = c("Los Angeles", "San Francisco"), effect_size = c(25.22, 15.99), standard_error = c(11.27, 12.66))
meta_analysis <- rma(data = df, yi = effect_size, sei = standard_error, slab = city)
df <- rbind(
df,
c("Meta-Analysis", meta_analysis$beta[1], meta_analysis$se[1])
)
ggplot(df, aes(x = city, y = effect_size)) +
geom_point()+
geom_errorbar(ymin = effect_size + 1.96 * standard_error, ymax = effect_size + 1.96 * standard_error)
df
ggplot(df, aes(x = city, y = effect_size)) +
geom_point()+
geom_errorbar(aes(ymin = effect_size + 1.96 * standard_error, ymax = effect_size + 1.96 * standard_error))
?geom_errorbar
ggplot(df, aes(x = city, y = effect_size)) +
geom_point()+
geom_errorbar(aes(ymin = effect_size - 1.96 * standard_error, ymax = effect_size + 1.96 * standard_error))
df$lower_95_ci <- df$effect_size - 1.96 * df$standard_error
df$upper_95_ci <- df$effect_size + 1.96 * df$standard_error
df
library(tidyverse)
df <- data.frame(city = c("Los Angeles", "San Francisco"), effect_size = c(25.22, 15.99), standard_error = c(11.27, 12.66))
meta_analysis <- rma(data = df, yi = effect_size, sei = standard_error, slab = city)
df <- rbind(
df,
c("Meta-Analysis", meta_analysis$beta[1], meta_analysis$se[1])
)
df <- df %>%
mutate(
lower_95_ci = effect_size - 1.96 * standard_error,
upper_95_ci = effect_size + 1.96 * standard_error
)
View(df)
df$effect_size
df$effect_size = as.numeric(df$effect_size)
df$standard_error = as.numeric(df$standard_error)
ggplot(df, aes(x = city, y = effect_size)) +
geom_point()+
geom_errorbar(aes(ymin = effect_size - 1.96 * standard_error, ymax = upper_95_ci))
ggplot(df, aes(x = city, y = effect_size)) +
geom_point()+
geom_errorbar(aes(ymin = effect_size - 1.96 * standard_error, ymax = effect_size + 1.96 * standard_error))
df <- df %>%
mutate(
city = factor(city, levels = c("Los Angeles", "San Francisco", "Meta-Analysis"))
effect_size = as.numeric(effect_size),
df <- df %>%
mutate(
city = factor(city, levels = c("Los Angeles", "San Francisco", "Meta-Analysis")),
effect_size = as.numeric(effect_size),
standard_error = as.numeric(standard_error)
) %>%
ggplot(df, aes(x = city, y = effect_size)) +
geom_point()+
geom_errorbar(aes(ymin = effect_size - 1.96 * standard_error, ymax = effect_size + 1.96 * standard_error))
